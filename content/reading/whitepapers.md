[Attention Is All You Need](https://arxiv.org/abs/1706.03762)
[BERT: Pre-training of Deep Bidirectional Transformers](https://arxiv.org/abs/1810.04805)
[ResNet: Deep Residual Learning](https://arxiv.org/abs/1512.03385)
[GPT-4 Technical Report](https://arxiv.org/abs/2303.08774)
